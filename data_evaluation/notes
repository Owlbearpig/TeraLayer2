Recreate matlab scripts in python


1. Simulate reflectance r_sim, given d0, lthz. Add noise. -> optimize abs(r(d, lthz)-r_sim)

CreaDatos.m
	% *** Construct THz wavelenghts ***
	lopt = [800 800.1 800.3 800.7]*1e-9 # Optical Wavelenghts
	d0 = [0.001 0.0003] # simulated thicknesses
	lthz = diff(lopt) # frequency(wl) diffs (6 in total)
	r = reflectance(d0, lthz) # reflectance (multir.m)

	r_noise = randn(1,6)/(10*w) # scaled(w=1,...,10) noise
	r_sim = r + r_noise

	di=[0.00085 0.00032] # x0, initial "guess"
    lb, hb=[0.0001 0.0001], [0.003 0.003] # optimization bounds

    options=optimoptions(@lsqcurvefit,'Algorithm','levenberg-marquardt',
                        'MaxFunctionEvaluations',2000000, 'MaxIterations', 200000, 'StepTolerance',1e-15)
    [d,resnorm] = lsqcurvefit(@multir,di,lthz,rr,lb,hb,options);

    d # result

multir.m
    ...

parametros.m (like consts.py)
    n=[1 1.50 2.8 1.50 1];
    a=1;
    thea=8*pi/180;


2. Kopf_0-100, BG_1000, ref_1000x. (f (MHz), ampl. s., phase. s., ampl. r., phase. r.,). Real measurements ?

Process3Layers(1-6) scripts
    r=dlmread('ref_1000x.csv', ',', 1, 0)
    b=dlmread('BG_1000.csv', ',', 1, 0)

    s=dlmread('Kopf_1x_0001', ',', 1, 0) ...

    f=r(235:end-1,1)*MHz
    lam=c0/f

    rr=r(235:end-1,2)-b(235:end-1,2)
    ss=s(235:end-1,2)-b(235:end-1,2)

    T=ss./rr

    R=T.^2 # measured reflectivity


- Implementing least squares algorithm(levenberg-marquardt)...
    (should be in scipy.optimize)

########################################################################################################################
1. Get multir implemented and check output against multir.m. MultirFunctionEval.py == MultirFunctionEval.m.
(done, plots match)

2. benchmark 6 thz wavelengths (time per eval/convergence) i7-4820k @ 4.59 GHz
    - python            : (multir, 1.5 ms), (leasqr, 100.0 ms)
    - python numba      : (multir_numba, 0.11 ms), (leasqr: 11.6 ms)
    - octave            : (multir, 4.5 ms), (leasqr, 365.5 ms) # not checking if converged to 'correct' minima

3. can't get grid search to converge to correct x. -> how does lm work and why does it converge in this case? p0??
4. full bruteforce search shows that global minimum isn't what leastsq gives. What now??
5. some results give 'weird' reflectances, even though the loss is lower...

6. Assume initial guess is close to optimum -> small search space / tight bounds.
7. smooth function ...
8. minimize number of func evals.

9. considering the nfev in grid search (ecAlgo) will be n^3 with n the resolution we can probably never beat scipy opt.
if we also calculate the derivatives

10. calculate gradient analytically, should be possible

11. test calculated gradient/jacobian in scipy least_squares.
    -> numeric jacobian(if no jac is given) quite similar to analytical one. Both give same result.

12. implement most simple gradient descent algorithm, or similar one to what scipy is using since there nfew+njev <= 40
scipy default method:
"'trf' : Trust Region Reflective algorithm, particularly suitable
for large sparse problems with bounds. Generally robust method."

13. problem: 6 frequency minimum quite different from wide frequency minimum ...
problem is not finding minimum (simplex works fine) problem is it's wrong compared to 'full' range ...

14. which frequencies produce minimum at the 'right' parameters?
- full_range_mask works...
- wide_mask doesnt work

15. to test simplex optimization + freq. problem:
    - pick 'reasonable' bounds + rez (done)
    - do the same calculation for all 100 measurements
    - 6 freq. + 'full' range (check if mask is full range, look at signal) (420-1000 GHz = 656-235 - 1236-235) (done)
    - simplex vs bruteforce on the grid
    -> 4 calculations

16. Problem: (d1,d2,d3) and (d3,d2,d1) seems to have similar losses and are therefore hard to distinguish ...
    - Can the phase be used for anything???
        -> look at CW measurement evaluation, do we measure phase in the final setup?

17. benchmark 6 thz wavelengths(custom mask 420) (time per eval/convergence) i7-4820k @ 4.59 GHz
    - ExplicitEvalOptimizedClean + _minimize_neldermead     : 3.5 ms / convergence (1000 calls), scipy copy

18. to get below 1 ms implement C;
    - ExplicitEvalOptimizedClean
    - _minimize_neldermead (already exists but without bounds, https://github.com/matteotiziano/nelder-mead)

19. found out a lot of variables are repeated : )
    a0=-a, a1=-b, a2=b, a3=a, b0=a, b1=b, b2=-b, b3=-a, with a=0.19737935744311108, b=0.300922921527581
    f0_0 = [0.+13235.26131362j 0.+16379.02884655j 0.+20465.92663936j 0.+25181.57793875j 0.+26753.46170521j 0.+29897.22923814j]
    f0_1 = [0.+24705.82111877j 0.+30574.18718023j 0.+38203.06306014j 0.+47005.61215233j 0.+49939.79518306j 0.+55808.16124453j]
    f0_2 = [0.+13235.26131362j 0.+16379.02884655j 0.+20465.92663936j 0.+25181.57793875j 0.+26753.46170521j 0.+29897.22923814j]

20. benchmark C implementation of model + optimization,
    6 thz wavelengths(custom mask 420) (time per eval/convergence) i7-4820k @ 4.59 GHz
    - loss.c                     : 2-3 us / call (1000 calls)
    - loss.c + nelder_mead.c     : 400 us / convergence. nit: 77, nfev: 143 (1000 calls), github
    - loss.c + nelder_mead.c     : 570 us / convergence. nit: 100, nfev: 187 (1000 calls), github
    (tighter break condition criteria)
    - loss.c + nelder_mead.c     : 1363 us / convergence. nit: 100, nfev: 187 (1000 calls), github
    (tighter break condition criteria + Makefile_slow)

21. depending on x0 can go to negative values (e.g. [20, 580, 20], works for [25, 580, 25])
    -> should probably add bounds.

22. runtime increases with x0 distance to minimum
    -> can go above 1 ms (e.g. [10, 600, 10] converges to [44 630 44] in 1.1 ms)
    -> tighten tolx, tolf = 0.01 can reduce runtime to 0.9 ms

23. Benchmark optimized loss.c + simplex
    -> for x0 = [35 600 35]:
        -> 127 us on i7  (loss.c is too fast to time???)
        -> 900 us on redpitaya (Dual-Core ARM Cortex-A9 MPCore) (loss.c: 12.9 us / call)

24. recip LUT: values of denum in explicitEvalSimple seem to be bound between x = 0.5 and x = 2. -> 1/x is in [2, 0.5]

#####################################################

r with correct phase, r1:
# r0 = Mtilde[1,0]/Mtilde[0,0]  # "original" tmm package convention
# r1 = -Mtilde[0, 1] / Mtilde[1, 1]

and r0 = -np.conj(r1)

