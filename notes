Recreate matlab scripts in python


1. Simulate reflectance r_sim, given d0, lthz. Add noise. -> optimize abs(r(d, lthz)-r_sim)

CreaDatos.m
	% *** Construct THz wavelenghts ***
	lopt = [800 800.1 800.3 800.7]*1e-9 # Optical Wavelenghts
	d0 = [0.001 0.0003] # simulated thicknesses
	lthz = diff(lopt) # frequency(wl) diffs (6 in total)
	r = reflectance(d0, lthz) # reflectance (multir.m)

	r_noise = randn(1,6)/(10*w) # scaled(w=1,...,10) noise
	r_sim = r + r_noise

	di=[0.00085 0.00032] # x0, initial "guess"
    lb, hb=[0.0001 0.0001], [0.003 0.003] # optimization bounds

    options=optimoptions(@lsqcurvefit,'Algorithm','levenberg-marquardt',
                        'MaxFunctionEvaluations',2000000, 'MaxIterations', 200000, 'StepTolerance',1e-15)
    [d,resnorm] = lsqcurvefit(@multir,di,lthz,rr,lb,hb,options);

    d # result

multir.m
    ...

parametros.m (like consts.py)
    n=[1 1.50 2.8 1.50 1];
    a=1;
    thea=8*pi/180;


2. Kopf_0-100, BG_1000, ref_1000x. (f (MHz), ampl. s., phase. s., ampl. r., phase. r.,). Real measurements ?

Process3Layers(1-6) scripts
    r=dlmread('ref_1000x.csv', ',', 1, 0)
    b=dlmread('BG_1000.csv', ',', 1, 0)

    s=dlmread('Kopf_1x_0001', ',', 1, 0) ...

    f=r(235:end-1,1)*MHz
    lam=c0/f

    rr=r(235:end-1,2)-b(235:end-1,2)
    ss=s(235:end-1,2)-b(235:end-1,2)

    T=ss./rr

    R=T.^2 # measured reflectivity


- Implementing least squares algorithm(levenberg-marquardt)...
    (should be in scipy.optimize)

########################################################################################################################
1. Get multir implemented and check output against multir.m. MultirFunctionEval.py == MultirFunctionEval.m.
(done, plots match)

2. benchmark 6 thz wavelengths (time per eval/convergence) i7-4820k @ 4.59 GHz
    - python            : (multir, 1.5 ms), (leasqr, 100.0 ms)
    - python numba      : (multir_numba, 0.11 ms), (leasqr: 11.6 ms)
    - octave            : (multir, 4.5 ms), (leasqr, 365.5 ms) # not checking if converged to 'correct' minima

3. can't get grid search to converge to correct x. -> how does lm work and why does it converge in this case? p0??
4. full bruteforce search shows that global minimum isn't what leastsq gives. What now??
5. some results give 'weird' reflectances, even though the loss is lower...

6. Assume initial guess is close to optimum -> small search space / tight bounds.
7. smooth function ...
8. minimize number of func evals.

9. considering the nfev in grid search (ecAlgo) will be n^3 with n the resolution we can probably never beat scipy opt.
if we also calculate the derivatives

10. calculate gradient analytically, should be possible

11. test calculated gradient/jacobian in scipy least_squares.
    -> numeric jacobian(if no jac is given) quite similar to analytical one. Both give same result.

12. implement most simple gradient descent algorithm, or similar one to what scipy is using since there nfew+njev <= 40
scipy default method:
"'trf' : Trust Region Reflective algorithm, particularly suitable
for large sparse problems with bounds. Generally robust method."

13.
